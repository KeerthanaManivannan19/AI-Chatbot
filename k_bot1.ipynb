{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb782c5-5443-4ed6-a3df-167ff257c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "from langchain.agents import *\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "import pymysql\n",
    "from langchain.agents import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a562c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_host = 'localhost'\n",
    "mysql_user = 'root'\n",
    "mysql_password = 'root'\n",
    "mysql_database = 'School_management_system'\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host=mysql_host,\n",
    "    user=mysql_user,\n",
    "    password=mysql_password,\n",
    "    auth_plugin='mysql_native_password',\n",
    "    database=mysql_database\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "excel_data = pd.read_excel('dataset.xlsx', sheet_name=None)\n",
    "\n",
    "for sheet_name, df in excel_data.items():\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    sheet_name_lower = sheet_name.lower()\n",
    "\n",
    "    columns = \", \".join(f\"{col} VARCHAR(255)\" for col in df.columns)\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS {sheet_name_lower} ({columns})\"\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        values = \", \".join(f\"'{value}'\" for value in row)\n",
    "        insert_data_query = f\"INSERT INTO {sheet_name_lower} VALUES ({values})\"\n",
    "        cursor.execute(insert_data_query)\n",
    "\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e41205-8043-4224-bafd-7fbe72eb5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_chat_history(dir_path):\n",
    "    \"\"\"read user's chat history\"\"\"\n",
    "\n",
    "    file_name = \"history.json\"\n",
    "    file_path = dir_path + \"/\" + file_name\n",
    "    user_chat_history = []\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        try:\n",
    "            user_chat_history = json.load(f)\n",
    "            return user_chat_history\n",
    "        except ValueError:\n",
    "            return user_chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded07954-d8db-4fd3-999a-f059c61cbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_history(dir_path):\n",
    "    \"\"\"create empty user session file for record chat history\"\"\"\n",
    "\n",
    "    file_name = \"history.json\"\n",
    "    file_path = dir_path + \"/\" + file_name\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1001e1d-0e8e-4f47-b4be-0b1d6519ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chat_history(dir_path, k, chat_history, user_message, ai_response):\n",
    "    \"\"\"update user's chat history\"\"\"\n",
    "\n",
    "    file_name = \"history.json\"\n",
    "    file_path = dir_path + \"/\" + file_name\n",
    "\n",
    "    converasation = {\n",
    "        \"input\": user_message,\n",
    "        \"output\": ai_response\n",
    "    }\n",
    "\n",
    "    # append the last conversation at last\n",
    "    chat_history.append(converasation)\n",
    "\n",
    "    # store only the last \"k\" conversations\n",
    "    if chat_history is not None and len(chat_history) > k:\n",
    "        chat_history = chat_history[-k:]\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(chat_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9328527b-f38e-4e92-8ee6-5b766ef6913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    return ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, model_kwargs={\"top_p\": 0.1}, verbose=False , openai_api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbbd658-e4e9-4547-bda6-a32a2e7f16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sql():\n",
    "    pymysql.connect(db='School_management_system', user='root', passwd='root', host='localhost', port=3306)\n",
    "    return  SQLDatabase.from_uri(\"mysql+pymysql://root:root@localhost/School_management_system\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49cf267-b346-4674-ac62-b2b7330f3c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to quit\n",
      "Enter a prompt: Hi\n",
      "general\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "\n",
      "Enter a prompt: Who is class teacher of 6A\n",
      "database\n",
      "Priya\n",
      "\n",
      "\n",
      "\n",
      "Enter a prompt: what is the highest marks in maths\n",
      "database\n",
      "0.98\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "def chat_with_sql():\n",
    "    turbo_llm = load_model()\n",
    "    # connection()\n",
    "    db = load_sql()\n",
    "\n",
    "    \n",
    "    file_path = \"C:/Users/HP/Chatbot/history.json\"\n",
    "    dir_path = \"C:/Users/HP/Chatbot/\"\n",
    "    print(\"Type 'exit' to quit\")\n",
    "\n",
    "    while True:\n",
    "        user_question = input(\"Enter a prompt: \").lower()\n",
    "\n",
    "        # Check if the user wants to exit\n",
    "        if user_question == 'exit':\n",
    "            print('Exiting...')\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Classify user's question as 'general' or 'database'\n",
    "            classification_prompt = f\"Is the question related to student databases? The question includes keywords such as teacher, class, marks, student, or subject. Classify the user's question: '{user_question}'. Enter 'general' or 'database'.\"\n",
    "            \n",
    "            classification_messages = [HumanMessage(content=classification_prompt)]\n",
    "            classification_result = turbo_llm.invoke(classification_messages).content\n",
    "            print(classification_result)\n",
    "\n",
    "            conversation_buffer_window_memory = 5\n",
    "            memory = ConversationBufferWindowMemory(k=conversation_buffer_window_memory, return_messages=True)\n",
    "\n",
    "            if os.path.exists(file_path):\n",
    "                create_chat_history(dir_path)\n",
    "\n",
    "            chat_history = read_chat_history(dir_path)\n",
    "\n",
    "            if chat_history is not None and len(chat_history) > 0:\n",
    "                for chat in chat_history:\n",
    "                    usr_msg = chat[\"input\"]\n",
    "                    ai_resp = chat[\"output\"]\n",
    "                    memory.save_context({\"input\": usr_msg}, {\"output\": ai_resp})\n",
    "\n",
    "\n",
    "            if classification_result == 'database':\n",
    "              \n",
    "\n",
    "                # Handle database-related question\n",
    "                try:\n",
    "\n",
    "                    # Create SQL agent and provide a template for database questions\n",
    "                    toolkit = SQLDatabaseToolkit(db=db,llm=turbo_llm)\n",
    "                    agent_executor = create_sql_agent(\n",
    "                        llm=turbo_llm,\n",
    "                        toolkit=toolkit,\n",
    "                        verbose=False,\n",
    "                        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "                        memory=memory\n",
    "                    )\n",
    "\n",
    "                    template = f\"\"\"Explore the student database and extract relevant information.\n",
    "                                Organize the findings into the appropriate table for a clear and insightful overview.\n",
    "                                User Question: {user_question}\n",
    "                                Please feel free to ask anything else, and I'll do my best to assist you!\n",
    "                            \"\"\"\n",
    "\n",
    "                    output = agent_executor.run(user_question)\n",
    "                    \n",
    "                    print(output)\n",
    "                    print(\"\\n\\n\")\n",
    "\n",
    "                    update_chat_history(dir_path, 5, chat_history, user_question, output)\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Handle exceptions related to database questions\n",
    "                    handle_exception(e, turbo_llm)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # Handle general questions\n",
    "                try:\n",
    "\n",
    "                    # Create a template for general questions\n",
    "                    template = f\"\"\"The user asked: '{user_question}'.\n",
    "                        Context:\n",
    "                        {chat_history}\n",
    "    \n",
    "                        Please provide a helpful and friendly response to the user's question.\n",
    "                        \n",
    "                        \"\"\"\n",
    "                    # Create a conversation chain for general questions\n",
    "                    conversation_with_summary = ConversationChain(\n",
    "                                                    llm=turbo_llm,\n",
    "                                                    memory=memory,\n",
    "                                                    verbose=False\n",
    "                                                    )\n",
    "\n",
    "                    output = conversation_with_summary.predict(input=template)\n",
    "                    print(output)\n",
    "                    print(\"\\n\\n\")\n",
    "\n",
    "                    update_chat_history(dir_path, 5, chat_history, user_question, output)\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Handle exceptions related to general questions\n",
    "                    handle_exception(e, turbo_llm)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle classification errors\n",
    "            handle_exception(e, turbo_llm)\n",
    "\n",
    "def handle_exception(exception, llm_instance):\n",
    "    # Handle exceptions by invoking the model with default text\n",
    "    text = f\"Describe the encountered error in detail, providing both a comprehensive essay and a concise summary highlighting the key points. \\n Error: {exception} o\"\n",
    "    messages = [HumanMessage(content=text)]\n",
    "    res = llm_instance.invoke(messages)\n",
    "    print(res)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "chat_with_sql()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e490fb4-14e8-46ea-a1bf-b6c05f5d0e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce4e6a-4270-4bbd-9afe-7363f17de541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8eb3b7-fdf8-4f4c-a407-973d62593781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
